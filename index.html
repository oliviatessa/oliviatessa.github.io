<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
  <meta name="description" content="" />
  <meta name="author" content="" />
  <link href="https://fonts.googleapis.com/css?family=Lato:100,300,400,700,900" rel="stylesheet" />
  <link rel="icon" type="image/x-icon" href="./assets/favicon.jpg">

  <title>Olivia T. Zahn</title>
  <!--
Reflux Template
https://templatemo.com/tm-531-reflux
-->
  <!-- Bootstrap core CSS -->
  <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet" />

  <!-- Additional CSS Files -->
  <link rel="stylesheet" href="assets/css/fontawesome.css" />
  <link rel="stylesheet" href="assets/css/templatemo-style.css" />
  <link rel="stylesheet" href="assets/css/owl.css" />
  <link rel="stylesheet" href="assets/css/lightbox.css" />
</head>
<!-- TODO: 
- check how everything looks on bigger macbook and monitor
-->

<body>
  <div id="page-wraper">
    <!-- Sidebar Menu -->
    <div class="responsive-nav">
      <i class="fa fa-bars" id="menu-toggle"></i>
      <div id="menu" class="menu">
        <i class="fa fa-times" id="menu-close"></i>
        <div class="container">
          <div class="image">
            <img src="assets/images/author-image.jpg" alt="" />
          </div>
          <div class="author-content">
            <h4>Olivia T. Zahn</h4>
            <p>Physics Ph.D. candidate</p>
            <p>Kutz Research Group</p>
            <p>University of Washington</p>
          </div>
          <nav class="main-nav" role="navigation">
            <ul class="main-menu">
              <li><a href="#section1">Research Projects</a></li>
              <li><a href="#section2">Publications</a></li>
              <li><a href="#section3">CV</a></li>
            </ul>
          </nav>
          <div class="social-network">
            <ul class="social-icons">
              <li>
                <a target="_blank" rel="noopener noreferrer"
                  href="https://scholar.google.com/citations?user=GlAnMvcAAAAJ&hl=en&oi=ao"><i
                    class="fa fa-google social"></i></a>
              </li>
              <li>
                <a target="_blank" rel="noopener noreferrer"
                  href="https://www.linkedin.com/in/olivia-zahn-78b11a133/"><i
                    class="fa fa-linkedin social"></i></a>
              </li>
              <li>
                <a target="_blank" rel="noopener noreferrer"
                  href="https://github.com/oliviatessa"><i
                    class="fa fa-github social"></i></a>
              </li>
            </ul>
          </div>
        </div>
      </div>
    </div>

    <section class="section about-me" data-section="section1">
      <div class="container">
        <div class="section-heading">
          <h2>Research Projects</h2>
          <div class="line-dec"></div>
          <span>
            My research is focused on using deep learning to model complex
            dynamic systems. I am interested in biological systems modeling,
            network dynamics, model compression, reduced order modeling,
            and the relationship between task complexity and network structure.
          </span>
        </div>
        <div class="left-image-post">
          <div class="row">
            <div class="col-md-6">
              <div class="left-image">
                <img src="assets/images/mothprunecover.jpg" alt="" />
              </div>
            </div>
            <div class="col-md-6">
              <div class="right-text">
                <h4>MothPruning</h4>
                <p>
                  We develop a framework that combines model predictive
                  control on an established flight dynamics model and deep
                  neural networks (DNNs) to create an efficient method for
                  solving the inverse problem of flight control. We turn to
                  natural systems for inspiration since they inherently
                  demonstrate network pruning with the consequence of yielding
                  more efficient networks for a specific set of tasks. This
                  bio-inspired approach allows us to leverage network pruning
                  to optimally sparsify a DNN architecture to perform flight
                  tasks with as few neural connections as possible.
                </p>
                <div class="white-button">
                  <a target="_blank" rel="noopener noreferrer"
                    href="https://github.com/oliviatessa/MothPruning#mothpruning">Read More</a>
                </div>
              </div>
            </div>
          </div>
        </div>

        <div class="right-image-post">
          <div class="row">
            <div class="col-md-6">
              <div class="left-text">
                <h4>DNN Motif Analysis</h4>
                <p>
                  We are quantifying the distribution of network motifs of sparse neural networks
                  trained to model a biological control task. Complex networks across many domains are made up of
                  statistically significant, subgraphs called network motifs.
                  Network motifs have been shown to be indicative of network functionality in control systems.
                  The DNNs in this study are trained to model insect flight control
                  and are sparsified via neural network pruning.
                  We have developed our own network motif mining algorithm
                  based around using the masking matrices of the pruned networks.
                </p>
                <div class="white-button">
                  <a target="_blank" rel="noopener noreferrer"
                    href="https://github.com/oliviatessa/MothMotifs#mothmotifs">Read More</a>
                </div>
              </div>
            </div>
            <div class="col-md-6">
              <div class="right-image">
                <img src="assets/images/motif_fig.jpg" alt="" />
              </div>
            </div>
          </div>
        </div>

        <div class="left-image-post left-image-post-border">
          <div class="row">
            <div class="col-md-6">
              <div class="left-image">
                <img src="assets/images/pnif_fig.jpg" alt="" />
              </div>
            </div>
            <div class="col-md-6">
              <div class="right-text">
                <h4>pNIF</h4>
                <p>
                  Model compression is important for modeling high-dimensional flow fields.
                  NIF is a mesh-agnostic, dimensionality reduction paradigm for modeling
                  complex spatio-temporal fields. NIF has a hypernet structure that isolates
                  the spatial complexity from the parameter complexity and
                  is capable of reconstructing complex spatio-temporal flow fields with parameters
                  that amount to a fraction of the dimensionality of the dataset.
                  This can be further reduced by neural network pruning. Here, we use
                  the method of neural network pruning to further reduce the computational complexity of NIF.
                </p>
                <div class="white-button">
                  <a target="_blank" rel="noopener noreferrer"
                    href="https://github.com/oliviatessa/pNIF#pruned-neural-implicit-flow-pnif">Read More</a>
                </div>
              </div>
            </div>
          </div>
        </div>

        <div class="right-image-post">
          <div class="row">
            <div class="left-text">
              <h4>Sparse ResNet-18</h4>
              <p>
                In this project, we sought to explore the relationship between image dataset
                complexity and the number of convolutional neural network (CNN)
                filters necessary for accurate image classification. We
                compared the maximum sparsity achieved via neural network
                pruning across networks trained on three different canonical
                datasets (MNIST, CIFAR-10, and CIFAR-100). We found that the
                maximum achievable sparsity is correlated with the task
                complexity of the dataset. Simpler tasks, such as
                classifying MNIST digits, can be done with fewer parameters
                than more challenging tasks (classifying 10 colored image
                classes or 100 colored image classes).
              </p>
              <div class="white-button">
                <a target="_blank" rel="noopener noreferrer" href="./sparse_resnet.html">Read More</a>
              </div>
            </div>
          </div>
        </div>

        <div class="right-image-post">
          <div class="row">
            <div class="left-text">
              <h4>Sparse Sensor Placement</h4>
              <p>
                Sensor placement is an important and ubiquitous problem across the engineering and
                physical sciences for tasks such as reconstruction, forecasting and control. In this
                work, we develop two algorithms for optimizing sensor locations for use with shallow
                decoder networks (SDNs): one which is a linear selection algorithm based upon QR (Q-SDN),
                and one which is a nonlinear selection algorithm based upon neural network pruning (P-SDN).
                We demonstrate our sensor selection algorithms on two example data sets from fluid dynamics.
                Moreover, we provide a detailed comparison between our linear (Q-SDN) and nonlinear
                (P-SDN) algorithms with traditional linear embedding techniques (proper orthogonal decomposition) and QR
                greedy selection.
            </div>
          </div>
        </div>

        <div class="right-image-post">
          <div class="row">
            <div class="left-text">
              <h4>Shallow Recurrent Decoder Network</h4>
              <p>
                Sensing is a universal task in science and engineering. These tasks are exceptionally challenging to
                achieve with limited sensors, corrupt and missing data, and noisy measurements. Here, we propose a
                <b>SH</b>allow <b>RE</b>current <b>D</b>ecoder (SHRED) neural network structure which incorporates a
                recurrent neural network (LSTM) to learn a latent representation of the temporal dynamics of the sensor,
                and a shallow decoder that learns an end-to-end mapping between this latent representation and the
                high-dimensional state space. SHRED enables faithful reconstructions with far fewer sensors, outperforms
                existing techniques when more measurements are available, and is agnostic towards sensor placement.
              </p>
            </div>
          </div>

        </div>
      </div>
    </section>

    <section class="section my-work" data-section="section2">
      <div class="container">
        <div class="section-heading">
          <h2>Publications</h2>
          <div class="line-dec"></div>
          <span>
            <p align="left"><b>Zahn, Olivia</b>,
              Jorge Bustamante Jr, Callin Switzer, Thomas L. Daniel, and J. Nathan Kutz.
              “Pruning deep neural networks generates a sparse, bio-inspired nonlinear controller for
              insect flight.” PLoS Computational Biology 18.9 (2022): e1010512.
              <a target="_blank" rel="noopener noreferrer" href="https://doi.org/10.1371/journal.pcbi.1010512">
                https://doi.org/10.1371/journal.pcbi.1010512
              </a>
            </p>
            <p align="left"><b>Zahn, Olivia</b>, and Michael J. Henry. “Model order reduction of ResNet-18 using
              magnitude-based channel pruning.” In progress. (exp. 2023)</p>
            <p align="left">Williams, Jan, <b>Olivia Zahn</b>, and J. Nathan Kutz. “Data-driven sensor placement with
              shallow decoder networks.”
              <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2202.05330">
                arXiv preprint arXiv:2202.05330 (2022).
              </a>
            </p>
            <p align="left">Williams, Jan, <b>Olivia Zahn</b>, and J. Nathan Kutz. “Sensing with Shallow Recurrent
              Decoder Networks.” In progress (exp. 2023).</p>
          </span>
        </div>
      </div>
    </section>

    <section class="section my-services" data-section="section3">
      <div class="container">
        <div class="section-heading">
          <h2>CV</h2>
          <div class="line-dec"></div>
          <object style="width:100%; height:50rem" type="application/pdf" data="./assets/otz_CV_wo_address.pdf">
            <p>Insert your error message here, if the PDF cannot be displayed.</p>
          </object>
        </div>
      </div>
    </section>
  </div>

  <!-- Scripts -->
  <!-- Bootstrap core JavaScript -->
  <script src="vendor/jquery/jquery.min.js"></script>
  <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

  <script src="assets/js/isotope.min.js"></script>
  <script src="assets/js/owl-carousel.js"></script>
  <script src="assets/js/lightbox.js"></script>
  <script src="assets/js/custom.js"></script>
  <script>
    //according to loftblog tut
    $(".main-menu li:first").addClass("active");

    var showSection = function showSection(section, isAnimate) {
      var direction = section.replace(/#/, ""),
        reqSection = $(".section").filter(
          '[data-section="' + direction + '"]'
        ),
        reqSectionPos = reqSection.offset().top - 0;

      if (isAnimate) {
        $("body, html").animate(
          {
            scrollTop: reqSectionPos,
          },
          800
        );
      } else {
        $("body, html").scrollTop(reqSectionPos);
      }
    };

    var checkSection = function checkSection() {
      $(".section").each(function () {
        var $this = $(this),
          topEdge = $this.offset().top - 80,
          bottomEdge = topEdge + $this.height(),
          wScroll = $(window).scrollTop();
        if (topEdge < wScroll && bottomEdge > wScroll) {
          var currentId = $this.data("section"),
            reqLink = $("a").filter("[href*=\\#" + currentId + "]");
          reqLink
            .closest("li")
            .addClass("active")
            .siblings()
            .removeClass("active");
        }
      });
    };

    $(".main-menu").on("click", "a", function (e) {
      e.preventDefault();
      showSection($(this).attr("href"), true);
    });

    $(window).scroll(function () {
      checkSection();
    });
  </script>
</body>

</html>